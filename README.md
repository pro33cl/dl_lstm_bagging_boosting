# üìò Deep Learning & NLP: LSTM + Word Embeddings + Bagging & Boosting

Notebook: dl_lstm_bagging_boosting.ipynb

üß† Descripci√≥n General

Este repositorio contiene un notebook que desarrolla un flujo completo de Procesamiento de Lenguaje Natural (NLP) aplicando t√©cnicas modernas de Deep Learning y Machine Learning sobre un dataset de noticias. El objetivo es predecir el nivel de viralidad de cada art√≠culo mediante modelos tanto tradicionales como basados en redes neuronales.
El proyecto integra procesamiento de texto, embeddings, redes LSTM, t√©cnicas de ensamble y an√°lisis de m√©tricas, ofreciendo una visi√≥n pr√°ctica del pipeline t√≠pico utilizado en problemas reales de clasificaci√≥n de texto.

üìÇ Contenidos del Notebook

El notebook se organiza en actividades que abarcan todo el ciclo de modelamiento:

1Ô∏è‚É£ Exploraci√≥n de Datos (EDA)

Carga del dataset news1.csv.

Divisi√≥n en training y test.

Exploraci√≥n de palabras, conteos y patrones.

Identificaci√≥n del objetivo: n√∫mero de veces que el art√≠culo fue compartido.

2Ô∏è‚É£ Word Embeddings

Uso de un modelo Word2Vec preentrenado.

Generaci√≥n de las secuencias de texto.

Construcci√≥n de la matriz de embeddings para alimentar los modelos.

3Ô∏è‚É£ Modelo LSTM (Deep Learning)

Implementaci√≥n de una red neuronal recurrente (LSTM).

Preparaci√≥n del pipeline de tokenizaci√≥n y padding.

Evaluaci√≥n del modelo mediante:

Accuracy

Matriz de confusi√≥n

Curva ROC y AUC

4Ô∏è‚É£ Predicciones y An√°lisis de Errores

Predicci√≥n de nuevas observaciones del conjunto de noticias.

An√°lisis de casos correctamente clasificados.

Comentarios sobre errores y desaf√≠os del modelo.

5Ô∏è‚É£ T√©cnicas de Ensamble

Bagging

Boosting

Comparaci√≥n conceptual entre t√©cnicas tradicionales y Deep Learning.

üõ†Ô∏è Tecnolog√≠as Utilizadas

- Python 3

- NumPy

- Pandas

- Matplotlib / Seaborn

- TensorFlow / Keras

- Gensim (Word2Vec)

- Scikit-learn
